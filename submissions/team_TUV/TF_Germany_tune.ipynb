{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38820215",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rr</th>\n",
       "      <th>tg</th>\n",
       "      <th>tn</th>\n",
       "      <th>tx</th>\n",
       "      <th>pp</th>\n",
       "      <th>hu</th>\n",
       "      <th>fg</th>\n",
       "      <th>qq</th>\n",
       "      <th>et</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-05-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>12.990000</td>\n",
       "      <td>7.42</td>\n",
       "      <td>17.630000</td>\n",
       "      <td>1008.9000</td>\n",
       "      <td>70.520004</td>\n",
       "      <td>2.88</td>\n",
       "      <td>205.0</td>\n",
       "      <td>2.765489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.759999</td>\n",
       "      <td>7.08</td>\n",
       "      <td>16.109999</td>\n",
       "      <td>1008.0000</td>\n",
       "      <td>79.690000</td>\n",
       "      <td>2.70</td>\n",
       "      <td>154.0</td>\n",
       "      <td>2.015525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>11.880000</td>\n",
       "      <td>8.66</td>\n",
       "      <td>16.779999</td>\n",
       "      <td>1007.7000</td>\n",
       "      <td>89.940000</td>\n",
       "      <td>2.49</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.339214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-04</th>\n",
       "      <td>6.3</td>\n",
       "      <td>8.670000</td>\n",
       "      <td>5.98</td>\n",
       "      <td>10.950000</td>\n",
       "      <td>1009.5000</td>\n",
       "      <td>94.128580</td>\n",
       "      <td>2.40</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.022122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-05</th>\n",
       "      <td>7.0</td>\n",
       "      <td>7.870000</td>\n",
       "      <td>3.90</td>\n",
       "      <td>13.219999</td>\n",
       "      <td>1015.2000</td>\n",
       "      <td>77.665000</td>\n",
       "      <td>1.87</td>\n",
       "      <td>137.0</td>\n",
       "      <td>1.604829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.470000</td>\n",
       "      <td>1.15</td>\n",
       "      <td>3.530000</td>\n",
       "      <td>1039.9000</td>\n",
       "      <td>84.810000</td>\n",
       "      <td>4.71</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.260880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.510000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>4.260000</td>\n",
       "      <td>1043.1000</td>\n",
       "      <td>85.750000</td>\n",
       "      <td>3.62</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.280443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.310000</td>\n",
       "      <td>-4.30</td>\n",
       "      <td>4.440000</td>\n",
       "      <td>1042.1000</td>\n",
       "      <td>95.075005</td>\n",
       "      <td>2.09</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.424098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.550000</td>\n",
       "      <td>-8.41</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>1040.6000</td>\n",
       "      <td>94.700005</td>\n",
       "      <td>1.57</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.360732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.380000</td>\n",
       "      <td>-4.84</td>\n",
       "      <td>-3.520000</td>\n",
       "      <td>1037.2001</td>\n",
       "      <td>94.533340</td>\n",
       "      <td>1.41</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.306081</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5359 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             rr         tg    tn         tx         pp         hu    fg  \\\n",
       "time                                                                      \n",
       "2002-05-01  0.0  12.990000  7.42  17.630000  1008.9000  70.520004  2.88   \n",
       "2002-05-02  0.0  11.759999  7.08  16.109999  1008.0000  79.690000  2.70   \n",
       "2002-05-03  0.0  11.880000  8.66  16.779999  1007.7000  89.940000  2.49   \n",
       "2002-05-04  6.3   8.670000  5.98  10.950000  1009.5000  94.128580  2.40   \n",
       "2002-05-05  7.0   7.870000  3.90  13.219999  1015.2000  77.665000  1.87   \n",
       "...         ...        ...   ...        ...        ...        ...   ...   \n",
       "2016-12-27  0.0   2.470000  1.15   3.530000  1039.9000  84.810000  4.71   \n",
       "2016-12-28  0.0   3.510000  0.50   4.260000  1043.1000  85.750000  3.62   \n",
       "2016-12-29  0.0  -1.310000 -4.30   4.440000  1042.1000  95.075005  2.09   \n",
       "2016-12-30  0.0  -4.550000 -8.41   0.890000  1040.6000  94.700005  1.57   \n",
       "2016-12-31  0.0  -4.380000 -4.84  -3.520000  1037.2001  94.533340  1.41   \n",
       "\n",
       "               qq        et  \n",
       "time                         \n",
       "2002-05-01  205.0  2.765489  \n",
       "2002-05-02  154.0  2.015525  \n",
       "2002-05-03  102.0  1.339214  \n",
       "2002-05-04   85.0  1.022122  \n",
       "2002-05-05  137.0  1.604829  \n",
       "...           ...       ...  \n",
       "2016-12-27   27.0  0.260880  \n",
       "2016-12-28   28.0  0.280443  \n",
       "2016-12-29   51.0  0.424098  \n",
       "2016-12-30   50.0  0.360732  \n",
       "2016-12-31   42.0  0.306081  \n",
       "\n",
       "[5359 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import keras_tuner as kt\n",
    "\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from numpy import empty\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from os import chdir\n",
    "from os import getcwd\n",
    "from os import listdir\n",
    "import math\n",
    "\n",
    "csv_file_path = 'D:/Arbeit PhD/Fachlich/z_Sonstiges/Groundwater challenge/data/Germany'\n",
    "chdir(csv_file_path)\n",
    "\n",
    "Y = pd.read_csv('heads.csv',decimal='.',index_col=0, delimiter=',', header=0,parse_dates=True)\n",
    "X_all = pd.read_csv('input_data.csv',decimal='.',index_col='time', delimiter=',', header=0,parse_dates=True)\n",
    "X = X_all['2002-05-01':' 2016-12-31']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af3e234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:'2011-12-31']\n",
    "X_test = X['2014-01-01':]\n",
    "X_valid = X['2012-01-01':'2013-12-31']\n",
    "Y_train = Y[:'2011-12-31']\n",
    "Y_test = Y['2014-01-01':]\n",
    "Y_valid = Y['2012-01-01':'2013-12-31']\n",
    "\n",
    "csv_file_path = 'D:\\Arbeit PhD\\Fachlich\\z_Sonstiges\\Groundwater challenge\\data'\n",
    "chdir(csv_file_path)\n",
    "from helper import *\n",
    "# data is normalized per column\n",
    "(dataset_train,dataset_test,dataset_valid,scaler_X,scaler_Y)=prepare_data(X_train,Y_train,X_valid,Y_valid,X_test,Y_test)\n",
    " \n",
    "iters=3\n",
    "n_steps_in=30\n",
    "n_steps_out=1\n",
    "\n",
    "# windows of 30 time steps as input and 1 time step (daily) as output are created\n",
    "x, y = split_sequences_y1(dataset_train, n_steps_in, n_steps_out)\n",
    "x_test, y_test = split_sequences_y1(dataset_test, n_steps_in, n_steps_out)\n",
    "x_valid, y_valid = split_sequences_y1(dataset_valid, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea744d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block is to set dropout active during training and testing (for Monte Carlo Dropout)\n",
    "import keras_tuner as kt\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "class Dropout(keras.layers.Dropout):\n",
    "    def __init__(self, rate, training=None, noise_shape=None, seed=None, **kwargs):\n",
    "        super(Dropout, self).__init__(rate, noise_shape=None, seed=None,**kwargs)\n",
    "        self.training = training\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        if 0. < self.rate < 1.:\n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "\n",
    "            def dropped_inputs():\n",
    "                return K.dropout(inputs, self.rate, noise_shape,\n",
    "                                 seed=self.seed)\n",
    "            if not training: \n",
    "                return K.in_train_phase(dropped_inputs, inputs, training=self.training)\n",
    "            return K.in_train_phase(dropped_inputs, inputs, training=training)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c88ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformer model is mostly in helper function\n",
    "from keras_tuner import HyperModel\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class Transformer_HyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(Transformer_HyperModel, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        \n",
    "    def build(self, hp):# 3 tunable parameters\n",
    "        head_size = hp.Int(\"head_size\", min_value=8, max_value=64) #, default=16\n",
    "        num_heads = 1\n",
    "        ff_dim = hp.Int(\"ff_dim\", min_value=1, max_value=8) #, default=4\n",
    "        num_transformer_blocks = 2 #, default=4\n",
    "        mlp_units = hp.Int(\"mlp_units\", min_value=10, max_value=200)\n",
    "        dropout = 0.1\n",
    "        mlp_dropout = 0.1\n",
    "        \n",
    "        model = build_model(self.input_shape, self.output_shape, head_size,num_heads,ff_dim,\n",
    "                                num_transformer_blocks,mlp_units,mlp_dropout)\n",
    "        model.compile(loss=\"mean_absolute_error\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4),metrics=[\"mean_absolute_error\"])\n",
    "        return model\n",
    "\n",
    "input_shape = x.shape[1:]\n",
    "output_shape = y.shape[1]\n",
    "\n",
    "hyper_model = Transformer_HyperModel(input_shape, output_shape)\n",
    "\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_mean_absolute_error',restore_best_weights=True, patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed3bbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 03m 05s]\n",
      "val_mean_absolute_error: 0.08501734584569931\n",
      "\n",
      "Best val_mean_absolute_error So Far: 0.060606248676776886\n",
      "Total elapsed time: 00h 18m 02s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30, 9)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 30, 9)        18          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 30, 9)        906         layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 30, 9)        0           multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 30, 9)        0           dropout[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 30, 9)        18          tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 30, 5)        50          layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30, 5)        0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 30, 9)        54          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 30, 9)        0           conv1d_1[0][0]                   \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 30, 9)        18          tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 30, 9)        906         layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 30, 9)        0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 30, 9)        0           dropout_2[0][0]                  \n",
      "                                                                 tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 30, 9)        18          tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 30, 5)        50          layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 30, 5)        0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 30, 9)        54          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 30, 9)        0           conv1d_3[0][0]                   \n",
      "                                                                 tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 30)           0           tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          3968        global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            129         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,189\n",
      "Trainable params: 6,189\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# tuning the models using random search\n",
    "tuner= kt.RandomSearch(\n",
    "        hyper_model,\n",
    "        overwrite=True,\n",
    "        objective='val_mean_absolute_error',\n",
    "        max_trials = 10,\n",
    "        directory='D:\\Arbeit PhD\\Fachlich\\z_Sonstiges\\Groundwater challenge',\n",
    "        project_name='TF Germany'\n",
    "        )\n",
    "\n",
    "tuner.search(\n",
    "        x,\n",
    "        y,\n",
    "        batch_size=24,\n",
    "        epochs=30,\n",
    "        validation_data=(x_valid,y_valid),\n",
    "        callbacks=[es_callback],\n",
    "        verbose=1)\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "Y_pred=best_model.predict(x_test)\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f4f5ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in D:\\Arbeit PhD\\Fachlich\\z_Sonstiges\\Groundwater challenge\\TF Germany\n",
      "Showing 10 best trials\n",
      "Objective(name='val_mean_absolute_error', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 23\n",
      "ff_dim: 5\n",
      "mlp_units: 128\n",
      "Score: 0.060606248676776886\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 28\n",
      "ff_dim: 1\n",
      "mlp_units: 142\n",
      "Score: 0.06879517436027527\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 39\n",
      "ff_dim: 5\n",
      "mlp_units: 160\n",
      "Score: 0.06976642459630966\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 49\n",
      "ff_dim: 5\n",
      "mlp_units: 21\n",
      "Score: 0.07517752796411514\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 18\n",
      "ff_dim: 1\n",
      "mlp_units: 112\n",
      "Score: 0.07579997926950455\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 20\n",
      "ff_dim: 8\n",
      "mlp_units: 197\n",
      "Score: 0.0847395807504654\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 48\n",
      "ff_dim: 2\n",
      "mlp_units: 70\n",
      "Score: 0.08501734584569931\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 27\n",
      "ff_dim: 4\n",
      "mlp_units: 185\n",
      "Score: 0.08571317046880722\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 52\n",
      "ff_dim: 6\n",
      "mlp_units: 27\n",
      "Score: 0.09037964791059494\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 16\n",
      "ff_dim: 7\n",
      "mlp_units: 30\n",
      "Score: 0.09723277390003204\n",
      "0.14006111066365975\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()\n",
    "\n",
    "#saving the model\n",
    "csv_file_path = 'D:\\Arbeit PhD\\Fachlich\\z_Sonstiges\\Groundwater challenge'\n",
    "chdir(csv_file_path)\n",
    "from tensorflow.keras.models import save_model\n",
    "best_model.save('TF_Germany_tune.h5')\n",
    "\n",
    "NSE=np.array([[None]*n_steps_out])\n",
    "MAE=np.array([[None]*n_steps_out])\n",
    "RMSE=np.array([[None]*n_steps_out])\n",
    "SAPE=np.array([[None]*n_steps_out])\n",
    "\n",
    "Y_pred_test=best_model.predict(x_test)\n",
    "y_correct_utf = scaler_Y.inverse_transform(y_test) # test\n",
    "yhat_utf = scaler_Y.inverse_transform(Y_pred_test) # test\n",
    "\n",
    "NSE[:]= np.array([1 - sum((yhat_utf[:,i]-y_correct_utf[:,i])**2)/sum((y_correct_utf[:,i]-np.mean(y_correct_utf[:,i]))**2)\n",
    "                  for i in range(n_steps_out)])\n",
    "MAE[:]=np.array([mean_absolute_error(y_correct_utf[:,i], yhat_utf[:,i]) for i in range(n_steps_out)])\n",
    "RMSE[:]=np.array([np.sqrt(np.mean((yhat_utf[:,i]-y_correct_utf[:,i])**2)) for i in range(n_steps_out)])\n",
    "SAPE[:] = np.array([np.abs((yhat_utf[:,i] - y_correct_utf[:,i])/(0.5*(y_correct_utf[:,i]+yhat_utf[:,i]))).mean()\n",
    "                         for i in range(n_steps_out)]) #mean absolute percent error\n",
    "print(np.mean(MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e440e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27feac42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307092c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41765479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2dfcf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "8362c94acb70529fb597ced4e020ad9ec7f0e835666f207c4442104931f7034b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
