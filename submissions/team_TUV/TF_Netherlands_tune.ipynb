{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38820215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5732, 9) (5696, 1)\n",
      "(36, 9)\n",
      "(5732, 9) (5732, 1)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import keras_tuner as kt\n",
    "\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from numpy import empty\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from os import chdir\n",
    "from os import getcwd\n",
    "from os import listdir\n",
    "import math\n",
    "\n",
    "csv_file_path = 'D:/Arbeit PhD/Fachlich/z_Sonstiges/Groundwater challenge/data/Netherlands'\n",
    "chdir(csv_file_path)\n",
    "\n",
    "Y_all = pd.read_csv('heads.csv',decimal='.',index_col=0, delimiter=',', header=0,parse_dates=True)\n",
    "X_all = pd.read_csv('input_data.csv',decimal='.', delimiter=',',index_col=0, header=0,parse_dates=True)\n",
    "\n",
    "Y_temp = Y_all['2000-01-01' : '2015-09-10']\n",
    "X = X_all['2000-01-01' : '2015-09-10']\n",
    "print(X.shape, Y_temp.shape)\n",
    "print(X[~(X.index.isin(Y_temp.index))].shape)\n",
    "Y = Y_temp.reindex(pd.date_range(start=Y_temp.index.min(),end=Y_temp.index.max(),freq='1D')) \n",
    "Y.interpolate(method='linear', inplace=True)  \n",
    "print(X.shape, Y.shape)\n",
    "print(Y.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af3e234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:'2011-12-31']\n",
    "X_test = X['2014-01-01':]\n",
    "X_valid = X['2012-01-01':'2013-12-31']\n",
    "\n",
    "Y_train = Y[:'2011-12-31']\n",
    "Y_test = Y['2014-01-01':]\n",
    "Y_valid = Y['2012-01-01':'2013-12-31']\n",
    "\n",
    "csv_file_path = 'D:\\Arbeit PhD\\Fachlich\\z_Sonstiges\\Groundwater challenge\\data'\n",
    "chdir(csv_file_path)\n",
    "from helper import *\n",
    "(dataset_train,dataset_test,dataset_valid,scaler_X,scaler_Y)=prepare_data(X_train,Y_train,X_valid,Y_valid,X_test,Y_test)\n",
    " \n",
    "iters=3\n",
    "n_steps_in=30\n",
    "n_steps_out=1\n",
    "\n",
    "x, y = split_sequences_y1(dataset_train, n_steps_in, n_steps_out)\n",
    "x_test, y_test = split_sequences_y1(dataset_test, n_steps_in, n_steps_out)\n",
    "x_valid, y_valid = split_sequences_y1(dataset_valid, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465050a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "class Dropout(keras.layers.Dropout):\n",
    "    def __init__(self, rate, training=None, noise_shape=None, seed=None, **kwargs):\n",
    "        super(Dropout, self).__init__(rate, noise_shape=None, seed=None,**kwargs)\n",
    "        self.training = training\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        if 0. < self.rate < 1.:\n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "\n",
    "            def dropped_inputs():\n",
    "                return K.dropout(inputs, self.rate, noise_shape,\n",
    "                                 seed=self.seed)\n",
    "            if not training: \n",
    "                return K.in_train_phase(dropped_inputs, inputs, training=self.training)\n",
    "            return K.in_train_phase(dropped_inputs, inputs, training=training)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c88ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import HyperModel\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class Transformer_HyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(Transformer_HyperModel, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        \n",
    "    def build(self, hp):\n",
    "        head_size = hp.Int(\"head_size\", min_value=8, max_value=64) #, default=16\n",
    "        num_heads = 1\n",
    "        ff_dim = hp.Int(\"ff_dim\", min_value=1, max_value=8) #, default=4\n",
    "        num_transformer_blocks = 2 #, default=4\n",
    "        mlp_units = hp.Int(\"mlp_units\", min_value=10, max_value=200)\n",
    "        dropout = 0.1\n",
    "        mlp_dropout = 0.1\n",
    "        \n",
    "        model = build_model(self.input_shape, self.output_shape, head_size,num_heads,ff_dim,\n",
    "                                num_transformer_blocks,mlp_units,mlp_dropout)\n",
    "        model.compile(loss=\"mean_absolute_error\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4),metrics=[\"mean_absolute_error\"])\n",
    "        return model\n",
    "\n",
    "input_shape = x.shape[1:]\n",
    "output_shape = y.shape[1]\n",
    "\n",
    "hyper_model = Transformer_HyperModel(input_shape, output_shape)\n",
    "\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_mean_absolute_error',restore_best_weights=True, patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed3bbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 03m 40s]\n",
      "val_mean_absolute_error: 0.058795493096113205\n",
      "\n",
      "Best val_mean_absolute_error So Far: 0.05589505657553673\n",
      "Total elapsed time: 00h 29m 06s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30, 9)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 30, 9)        18          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 30, 9)        2427        layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 30, 9)        0           multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 30, 9)        0           dropout[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 30, 9)        18          tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 30, 2)        20          layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30, 2)        0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 30, 9)        27          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 30, 9)        0           conv1d_1[0][0]                   \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 30, 9)        18          tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 30, 9)        2427        layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 30, 9)        0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 30, 9)        0           dropout_2[0][0]                  \n",
      "                                                                 tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 30, 9)        18          tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 30, 2)        20          layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 30, 2)        0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 30, 9)        27          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 30, 9)        0           conv1d_3[0][0]                   \n",
      "                                                                 tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 30)           0           tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 180)          5580        global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 180)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            181         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 10,781\n",
      "Trainable params: 10,781\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tuner= kt.RandomSearch(\n",
    "        hyper_model,\n",
    "        overwrite=True,\n",
    "        objective='val_mean_absolute_error',\n",
    "        max_trials = 10,\n",
    "        directory='D:\\Arbeit PhD\\Fachlich\\z_Sonstiges\\Groundwater challenge',\n",
    "        project_name='TF Netherlands'\n",
    "        )\n",
    "\n",
    "tuner.search(\n",
    "        x,\n",
    "        y,\n",
    "        batch_size=24,\n",
    "        epochs=30,\n",
    "        validation_data=(x_valid,y_valid),\n",
    "        callbacks=[es_callback],\n",
    "        verbose=1)\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "Y_pred=best_model.predict(x_test)\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f4f5ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in D:\\Arbeit PhD\\Fachlich\\z_Sonstiges\\Groundwater challenge\\TF Netherlands\n",
      "Showing 10 best trials\n",
      "Objective(name='val_mean_absolute_error', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 62\n",
      "ff_dim: 2\n",
      "mlp_units: 180\n",
      "Score: 0.05589505657553673\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 46\n",
      "ff_dim: 3\n",
      "mlp_units: 136\n",
      "Score: 0.058795493096113205\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 60\n",
      "ff_dim: 8\n",
      "mlp_units: 167\n",
      "Score: 0.06204243376851082\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 37\n",
      "ff_dim: 2\n",
      "mlp_units: 128\n",
      "Score: 0.06816931068897247\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 21\n",
      "ff_dim: 2\n",
      "mlp_units: 178\n",
      "Score: 0.06942184269428253\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 14\n",
      "ff_dim: 6\n",
      "mlp_units: 78\n",
      "Score: 0.0710093155503273\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 38\n",
      "ff_dim: 5\n",
      "mlp_units: 40\n",
      "Score: 0.07446075230836868\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 37\n",
      "ff_dim: 5\n",
      "mlp_units: 67\n",
      "Score: 0.08209089189767838\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 49\n",
      "ff_dim: 6\n",
      "mlp_units: 20\n",
      "Score: 0.08318252861499786\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 21\n",
      "ff_dim: 7\n",
      "mlp_units: 22\n",
      "Score: 0.09312786906957626\n",
      "0.07057179416986796\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()\n",
    "\n",
    "csv_file_path = 'D:\\Arbeit PhD\\Fachlich\\z_Sonstiges\\Groundwater challenge'\n",
    "chdir(csv_file_path)\n",
    "from tensorflow.keras.models import save_model\n",
    "best_model.save('TF_Netherlands_tune.h5')\n",
    "\n",
    "NSE=np.array([[None]*n_steps_out])\n",
    "MAE=np.array([[None]*n_steps_out])\n",
    "RMSE=np.array([[None]*n_steps_out])\n",
    "SAPE=np.array([[None]*n_steps_out])\n",
    "\n",
    "Y_pred_test=best_model.predict(x_test)\n",
    "\n",
    "y_correct_utf = scaler_Y.inverse_transform(y_test)\n",
    "yhat_utf = scaler_Y.inverse_transform(Y_pred_test)\n",
    "NSE[:]= np.array([1 - sum((yhat_utf[:,i]-y_correct_utf[:,i])**2)/sum((y_correct_utf[:,i]-np.mean(y_correct_utf[:,i]))**2)\n",
    "                  for i in range(n_steps_out)])\n",
    "MAE[:]=np.array([mean_absolute_error(y_correct_utf[:,i], yhat_utf[:,i]) for i in range(n_steps_out)])\n",
    "RMSE[:]=np.array([np.sqrt(np.mean((yhat_utf[:,i]-y_correct_utf[:,i])**2)) for i in range(n_steps_out)])\n",
    "SAPE[:] = np.array([np.abs((yhat_utf[:,i] - y_correct_utf[:,i])/(0.5*(y_correct_utf[:,i]+yhat_utf[:,i]))).mean()\n",
    "                         for i in range(n_steps_out)]) #mean absolute percent error\n",
    "\n",
    "print(np.mean(MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e440e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27feac42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307092c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41765479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2dfcf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "8362c94acb70529fb597ced4e020ad9ec7f0e835666f207c4442104931f7034b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
