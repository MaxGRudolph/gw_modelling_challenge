{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38820215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5354, 5) (5354, 1)\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRCP</th>\n",
       "      <th>TMAX</th>\n",
       "      <th>TMIN</th>\n",
       "      <th>Stage_m</th>\n",
       "      <th>ET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2002-05-01</th>\n",
       "      <td>5.334</td>\n",
       "      <td>17.222222</td>\n",
       "      <td>-1.111111</td>\n",
       "      <td>1.216093</td>\n",
       "      <td>3.841879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-02</th>\n",
       "      <td>0.000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>1.185614</td>\n",
       "      <td>2.320634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-03</th>\n",
       "      <td>9.652</td>\n",
       "      <td>14.444444</td>\n",
       "      <td>4.444444</td>\n",
       "      <td>1.295337</td>\n",
       "      <td>3.021346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-04</th>\n",
       "      <td>0.000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>1.252667</td>\n",
       "      <td>4.345549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2002-05-05</th>\n",
       "      <td>0.000</td>\n",
       "      <td>24.444444</td>\n",
       "      <td>2.777778</td>\n",
       "      <td>1.176471</td>\n",
       "      <td>5.193083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-22</th>\n",
       "      <td>0.000</td>\n",
       "      <td>2.222222</td>\n",
       "      <td>-11.111111</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.563036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-23</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>-3.888889</td>\n",
       "      <td>0.819872</td>\n",
       "      <td>0.665206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-24</th>\n",
       "      <td>0.000</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>-1.111111</td>\n",
       "      <td>0.862542</td>\n",
       "      <td>0.602258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-25</th>\n",
       "      <td>9.906</td>\n",
       "      <td>5.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.981408</td>\n",
       "      <td>0.544738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-12-26</th>\n",
       "      <td>0.000</td>\n",
       "      <td>6.111111</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>0.911308</td>\n",
       "      <td>0.741567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5354 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PRCP       TMAX       TMIN   Stage_m        ET\n",
       "2002-05-01  5.334  17.222222  -1.111111  1.216093  3.841879\n",
       "2002-05-02  0.000  10.000000   2.222222  1.185614  2.320634\n",
       "2002-05-03  9.652  14.444444   4.444444  1.295337  3.021346\n",
       "2002-05-04  0.000  20.000000   1.111111  1.252667  4.345549\n",
       "2002-05-05  0.000  24.444444   2.777778  1.176471  5.193083\n",
       "...           ...        ...        ...       ...       ...\n",
       "2016-12-22  0.000   2.222222 -11.111111  0.819872  0.563036\n",
       "2016-12-23  0.000   5.555556  -3.888889  0.819872  0.665206\n",
       "2016-12-24  0.000   5.555556  -1.111111  0.862542  0.602258\n",
       "2016-12-25  9.906   5.555556   0.555556  0.981408  0.544738\n",
       "2016-12-26  0.000   6.111111 -10.000000  0.911308  0.741567\n",
       "\n",
       "[5354 rows x 5 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import keras_tuner as kt\n",
    "\n",
    "from numpy import array\n",
    "from numpy import hstack\n",
    "from numpy import empty\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from os import chdir\n",
    "from os import getcwd\n",
    "from os import listdir\n",
    "import math\n",
    "\n",
    "csv_file_path = 'D:/Arbeit PhD/Fachlich/z_Sonstiges/Groundwater challenge/data/USA'\n",
    "chdir(csv_file_path)\n",
    "\n",
    "Y_all = pd.read_csv('heads.csv',decimal='.',index_col=0, delimiter=',', header=0,parse_dates=True)\n",
    "X_all = pd.read_csv('input_data.csv',decimal='.', delimiter=',',index_col=0, header=0,parse_dates=True)\n",
    "Y_temp = Y_all['2002-05-01':' 2016-12-26']\n",
    "X = X_all['2002-05-01':' 2016-12-26']\n",
    "# interpolate\n",
    "Y = Y_temp.reindex(pd.date_range(start=Y_temp.index.min(),end=Y_temp.index.max(),freq='1D')) \n",
    "Y.interpolate(method='linear', inplace=True)  \n",
    "print(X.shape, Y.shape)\n",
    "print(Y.isna().sum().sum())\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af3e234b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:'2011-12-31']\n",
    "X_test = X['2014-01-01':]\n",
    "X_valid = X['2012-01-01':'2013-12-31']\n",
    "\n",
    "Y_train = Y[:'2011-12-31']\n",
    "Y_test = Y['2014-01-01':]\n",
    "Y_valid = Y['2012-01-01':'2013-12-31']\n",
    "\n",
    "csv_file_path = 'D:\\Arbeit PhD\\Fachlich\\z_Sonstiges\\Groundwater challenge\\data'\n",
    "chdir(csv_file_path)\n",
    "from helper import *\n",
    "\n",
    "(dataset_train,dataset_test,dataset_valid,scaler_X,scaler_Y)=prepare_data(X_train,Y_train,X_valid,Y_valid,X_test,Y_test)\n",
    " \n",
    "iters=3\n",
    "n_steps_in=30\n",
    "n_steps_out=1\n",
    "\n",
    "x, y = split_sequences_y1(dataset_train, n_steps_in, n_steps_out)\n",
    "x_test, y_test = split_sequences_y1(dataset_test, n_steps_in, n_steps_out)\n",
    "x_valid, y_valid = split_sequences_y1(dataset_valid, n_steps_in, n_steps_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "465050a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras import backend as K\n",
    "class Dropout(keras.layers.Dropout):\n",
    "    def __init__(self, rate, training=None, noise_shape=None, seed=None, **kwargs):\n",
    "        super(Dropout, self).__init__(rate, noise_shape=None, seed=None,**kwargs)\n",
    "        self.training = training\n",
    "\n",
    "        \n",
    "    def call(self, inputs, training=None):\n",
    "        if 0. < self.rate < 1.:\n",
    "            noise_shape = self._get_noise_shape(inputs)\n",
    "\n",
    "            def dropped_inputs():\n",
    "                return K.dropout(inputs, self.rate, noise_shape,\n",
    "                                 seed=self.seed)\n",
    "            if not training: \n",
    "                return K.in_train_phase(dropped_inputs, inputs, training=self.training)\n",
    "            return K.in_train_phase(dropped_inputs, inputs, training=training)\n",
    "        return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c88ec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner import HyperModel\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "class Transformer_HyperModel(HyperModel):\n",
    "    def __init__(self, input_shape, output_shape):\n",
    "        super(Transformer_HyperModel, self).__init__()\n",
    "        \n",
    "        self.input_shape = input_shape\n",
    "        self.output_shape = output_shape\n",
    "        \n",
    "    def build(self, hp):\n",
    "        head_size = hp.Int(\"head_size\", min_value=8, max_value=64) #, default=16\n",
    "        num_heads = 1\n",
    "        ff_dim = hp.Int(\"ff_dim\", min_value=1, max_value=8) #, default=4\n",
    "        num_transformer_blocks = 2 #, default=4\n",
    "        mlp_units = hp.Int(\"mlp_units\", min_value=10, max_value=200)\n",
    "        dropout = 0.1\n",
    "        mlp_dropout = 0.1\n",
    "        \n",
    "        model = build_model(self.input_shape, self.output_shape, head_size,num_heads,ff_dim,\n",
    "                                num_transformer_blocks,mlp_units,mlp_dropout)\n",
    "        model.compile(loss=\"mean_absolute_error\",\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=1e-4),metrics=[\"mean_absolute_error\"])\n",
    "        return model\n",
    "\n",
    "input_shape = x.shape[1:]\n",
    "output_shape = y.shape[1]\n",
    "\n",
    "hyper_model = Transformer_HyperModel(input_shape, output_shape)\n",
    "\n",
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_mean_absolute_error',restore_best_weights=True, patience=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ed3bbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 04m 17s]\n",
      "val_mean_absolute_error: 0.06208235025405884\n",
      "\n",
      "Best val_mean_absolute_error So Far: 0.037721745669841766\n",
      "Total elapsed time: 00h 29m 30s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 30, 5)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization (LayerNorma (None, 30, 5)        10          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention (MultiHead (None, 30, 5)        1454        layer_normalization[0][0]        \n",
      "                                                                 layer_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 30, 5)        0           multi_head_attention[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add (TFOpLambd (None, 30, 5)        0           dropout[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_1 (LayerNor (None, 30, 5)        10          tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 30, 2)        12          layer_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 30, 2)        0           conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 30, 5)        15          dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_1 (TFOpLam (None, 30, 5)        0           conv1d_1[0][0]                   \n",
      "                                                                 tf.__operators__.add[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_2 (LayerNor (None, 30, 5)        10          tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_1 (MultiHe (None, 30, 5)        1454        layer_normalization_2[0][0]      \n",
      "                                                                 layer_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 30, 5)        0           multi_head_attention_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_2 (TFOpLam (None, 30, 5)        0           dropout_2[0][0]                  \n",
      "                                                                 tf.__operators__.add_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_3 (LayerNor (None, 30, 5)        10          tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 30, 2)        12          layer_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 30, 2)        0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 30, 5)        15          dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf.__operators__.add_3 (TFOpLam (None, 30, 5)        0           conv1d_3[0][0]                   \n",
      "                                                                 tf.__operators__.add_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 30)           0           tf.__operators__.add_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 142)          4402        global_average_pooling1d[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 142)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            143         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 7,547\n",
      "Trainable params: 7,547\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tuner= kt.RandomSearch(\n",
    "        hyper_model,\n",
    "        overwrite=True,\n",
    "        objective='val_mean_absolute_error',\n",
    "        max_trials = 10,\n",
    "        directory='D:\\Arbeit PhD\\Fachlich\\z_Sonstiges\\Groundwater challenge',\n",
    "        project_name='TF USA'\n",
    "        )\n",
    "\n",
    "tuner.search(\n",
    "        x,\n",
    "        y,\n",
    "        batch_size=24,\n",
    "        epochs=30,\n",
    "        validation_data=(x_valid,y_valid),\n",
    "        callbacks=[es_callback],\n",
    "        verbose=1)\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "Y_pred=best_model.predict(x_test)\n",
    "best_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f4f5ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results summary\n",
      "Results in D:\\Arbeit PhD\\Fachlich\\z_Sonstiges\\Groundwater challenge\\TF USA\n",
      "Showing 10 best trials\n",
      "Objective(name='val_mean_absolute_error', direction='min')\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 63\n",
      "ff_dim: 2\n",
      "mlp_units: 142\n",
      "Score: 0.037721745669841766\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 37\n",
      "ff_dim: 7\n",
      "mlp_units: 184\n",
      "Score: 0.04657990485429764\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 41\n",
      "ff_dim: 2\n",
      "mlp_units: 55\n",
      "Score: 0.04683830216526985\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 24\n",
      "ff_dim: 5\n",
      "mlp_units: 55\n",
      "Score: 0.04727715253829956\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 46\n",
      "ff_dim: 7\n",
      "mlp_units: 155\n",
      "Score: 0.04767649993300438\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 15\n",
      "ff_dim: 3\n",
      "mlp_units: 115\n",
      "Score: 0.048911694437265396\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 63\n",
      "ff_dim: 1\n",
      "mlp_units: 22\n",
      "Score: 0.05262492969632149\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 57\n",
      "ff_dim: 6\n",
      "mlp_units: 29\n",
      "Score: 0.05320991948246956\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 20\n",
      "ff_dim: 6\n",
      "mlp_units: 101\n",
      "Score: 0.056108880788087845\n",
      "Trial summary\n",
      "Hyperparameters:\n",
      "head_size: 36\n",
      "ff_dim: 4\n",
      "mlp_units: 89\n",
      "Score: 0.06208235025405884\n",
      "0.38780438715081944\n"
     ]
    }
   ],
   "source": [
    "tuner.results_summary()\n",
    "\n",
    "csv_file_path = 'D:\\Arbeit PhD\\Fachlich\\z_Sonstiges\\Groundwater challenge'\n",
    "chdir(csv_file_path)\n",
    "from tensorflow.keras.models import save_model\n",
    "best_model.save('TF_USA_tune.h5')\n",
    "\n",
    "NSE=np.array([[None]*n_steps_out])\n",
    "MAE=np.array([[None]*n_steps_out])\n",
    "RMSE=np.array([[None]*n_steps_out])\n",
    "SAPE=np.array([[None]*n_steps_out])\n",
    "\n",
    "Y_pred_test=best_model.predict(x_test)\n",
    "\n",
    "y_correct_utf = scaler_Y.inverse_transform(y_test)#test\n",
    "yhat_utf = scaler_Y.inverse_transform(Y_pred_test)#test\n",
    "\n",
    "NSE[:]= np.array([1 - sum((yhat_utf[:,i]-y_correct_utf[:,i])**2)/sum((y_correct_utf[:,i]-np.mean(y_correct_utf[:,i]))**2)\n",
    "                  for i in range(n_steps_out)])\n",
    "MAE[:]=np.array([mean_absolute_error(y_correct_utf[:,i], yhat_utf[:,i]) for i in range(n_steps_out)])\n",
    "RMSE[:]=np.array([np.sqrt(np.mean((yhat_utf[:,i]-y_correct_utf[:,i])**2)) for i in range(n_steps_out)])\n",
    "SAPE[:] = np.array([np.abs((yhat_utf[:,i] - y_correct_utf[:,i])/(0.5*(y_correct_utf[:,i]+yhat_utf[:,i]))).mean()\n",
    "                         for i in range(n_steps_out)]) #mean absolute percent error\n",
    "\n",
    "print(np.mean(MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e440e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27feac42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c307092c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41765479",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2dfcf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "8362c94acb70529fb597ced4e020ad9ec7f0e835666f207c4442104931f7034b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
